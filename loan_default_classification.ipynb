{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f8dcf5b",
   "metadata": {},
   "source": [
    "# Predicting Loan Defaults\n",
    "\n",
    "Predicting loan defaults is an extremely common use case for machine\n",
    "learning in banking, one of DataRobot's main target industries. As a\n",
    "loan officer, you are responsible for determining which loans are\n",
    "going to be the most profitable and worthy of lending money to. Based\n",
    "on a loan application from a potential client, you would like to\n",
    "predict whether the loan will be paid back in time.\n",
    "\n",
    "# Data\n",
    "\n",
    "You will be working with a loan dataset\n",
    "from LendingClub.com,\n",
    "a US peer-to-peer lending company. Your classification target is\n",
    "`is_bad`.\n",
    "\n",
    "# Task\n",
    "\n",
    "Partition your data into a holdout set and 5 stratified CV folds. Pick\n",
    "any two machine learning algorithms from the list below, and build a\n",
    "binary classification model with each of them:\n",
    "- Regularized Logistic Regression (scikit-learn)  \n",
    "- Gradient Boosting Machine (scikit-learn, XGBoost or LightGBM)\n",
    "- Neural Network (Keras), with the architecture of your choice\n",
    "\n",
    "Both of your models must make use of numeric, categorical, text, and\n",
    "date features. Compute out-of-sample LogLoss and F1 scores on\n",
    "cross-validation and holdout. Which one of your two models would you\n",
    "recommend to deploy? Explain your decision.\n",
    "\n",
    "*(Advanced, optional)*: Which 3 features are the most impactful for your model?\n",
    "\n",
    "Explain your methodology.\n",
    "\n",
    "# Data Dictionary\n",
    "|\tColumn Name|Type|Description|Category|\n",
    "|---|---|---|---|\n",
    "|`addr_state`|Categorical|Customer State|Customer\n",
    "|`annual_inc`|Numeric|Annual Income|Customer\n",
    "|`collections_12_mths_ex_med`|Numeric|(Credit based)|Customer\n",
    "|`debt-to-income`|Numeric|Ratio of debt to income|Loan\n",
    "|`delinq_2yrs`|Numeric|Any delinquency in last 2 years|Customer\n",
    "|`earliest_cr_line`|Date|First credit date|Customer\n",
    "|`emp_length`|Numeric|Length in current job|Customer\n",
    "|`emp_title`|Text|Employee Title|Customer\n",
    "|`home_ownership`|Categorical|Housing Status|Customer\n",
    "|`Id`|Numeric|Sequential number|Identifier\n",
    "|`initial_list_status`|Categorical|Loan status|Loan\n",
    "|`inq_last_6mths`|Numeric|Number of inquiries|Customer\n",
    "|`is_bad`|Numeric|1 or 0|Target\n",
    "|`mths_since_last_delinq`|Numeric|Months since last delinquency|Customer\n",
    "|`mths_since_last_major_derog`|Numeric|(Credit based)|Customer\n",
    "|`mths_since_last_record`|Numeric|Months since last record|Customer\n",
    "|`Notes`|Text|Notes taken by the administrator|Loan\n",
    "|`open_acc`|Numeric|(Credit based)|Customer\n",
    "|`pymnt_plan`|Categorical|Current Payment Plans|Customer\n",
    "|`policy_code`|Categorical|Loan type|Loan\n",
    "|`pub_rec`|Numeric|(Credit based)|Customer\n",
    "|`purpose`|Text|Purpose for the loan|Loan\n",
    "|`purpose_cat`|Categorical|Purpose category for the loan|Loan\n",
    "|`revol_bal`|Numeric|(Credit based)|Customer\n",
    "|`revol_util`|Numeric|(Credit based)|Customer\n",
    "|`total_acc`|Numeric|(Credit based)|Customer\n",
    "|`verification_status`|Categorical|Income Verified|Loan\n",
    "|`zip_code`|Categorical|Customer zip code|Customer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a8b0f1",
   "metadata": {},
   "source": [
    "In this notebook, I build a binary classification model of loan defaults using three ML methods \n",
    "- Logistic regression\n",
    "- Gradient boosting machine\n",
    "- Neural network \n",
    "\n",
    "Details of the task is shown in https://www.interviewquery.com/takehomes/datarobot-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cc5a93",
   "metadata": {},
   "source": [
    "# Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2d5b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone --branch datarobot_1 https://github.com/interviewquery/takehomes.git\n",
    "%cd takehomes/datarobot_1\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034acb38",
   "metadata": {},
   "source": [
    "# Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1598428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6faa4b",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72224b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>is_bad</th>\n",
       "      <th>emp_title</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>pymnt_plan</th>\n",
       "      <th>Notes</th>\n",
       "      <th>purpose_cat</th>\n",
       "      <th>...</th>\n",
       "      <th>mths_since_last_record</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_acc</th>\n",
       "      <th>initial_list_status</th>\n",
       "      <th>collections_12_mths_ex_med</th>\n",
       "      <th>mths_since_last_major_derog</th>\n",
       "      <th>policy_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Time Warner Cable</td>\n",
       "      <td>10</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>not verified</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>medical</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12087</td>\n",
       "      <td>12.1</td>\n",
       "      <td>44.0</td>\n",
       "      <td>f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>PC4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Ottawa University</td>\n",
       "      <td>1</td>\n",
       "      <td>RENT</td>\n",
       "      <td>39216.0</td>\n",
       "      <td>not verified</td>\n",
       "      <td>n</td>\n",
       "      <td>Borrower added on 04/14/11 &gt; I will be using...</td>\n",
       "      <td>debt consolidation</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10114</td>\n",
       "      <td>64.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>PC1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Kennedy Wilson</td>\n",
       "      <td>4</td>\n",
       "      <td>RENT</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>not verified</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>credit card</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81</td>\n",
       "      <td>0.6</td>\n",
       "      <td>8.0</td>\n",
       "      <td>f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>PC4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>TOWN OF PLATTEKILL</td>\n",
       "      <td>10</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>57500.0</td>\n",
       "      <td>not verified</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>debt consolidation</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10030</td>\n",
       "      <td>37.1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>PC2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Belmont Correctional</td>\n",
       "      <td>10</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>50004.0</td>\n",
       "      <td>VERIFIED - income</td>\n",
       "      <td>n</td>\n",
       "      <td>I want to consolidate my debt, pay for a vacat...</td>\n",
       "      <td>debt consolidation</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10740</td>\n",
       "      <td>40.4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>PC3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  is_bad             emp_title emp_length home_ownership  annual_inc  \\\n",
       "0   1       0     Time Warner Cable         10       MORTGAGE     50000.0   \n",
       "1   2       0     Ottawa University          1           RENT     39216.0   \n",
       "2   3       0        Kennedy Wilson          4           RENT     65000.0   \n",
       "3   4       0    TOWN OF PLATTEKILL         10       MORTGAGE     57500.0   \n",
       "4   5       0  Belmont Correctional         10       MORTGAGE     50004.0   \n",
       "\n",
       "  verification_status pymnt_plan  \\\n",
       "0        not verified          n   \n",
       "1        not verified          n   \n",
       "2        not verified          n   \n",
       "3        not verified          n   \n",
       "4   VERIFIED - income          n   \n",
       "\n",
       "                                               Notes         purpose_cat  ...  \\\n",
       "0                                                NaN             medical  ...   \n",
       "1    Borrower added on 04/14/11 > I will be using...  debt consolidation  ...   \n",
       "2                                                NaN         credit card  ...   \n",
       "3                                                NaN  debt consolidation  ...   \n",
       "4  I want to consolidate my debt, pay for a vacat...  debt consolidation  ...   \n",
       "\n",
       "  mths_since_last_record open_acc pub_rec  revol_bal  revol_util total_acc  \\\n",
       "0                    NaN     15.0     0.0      12087        12.1      44.0   \n",
       "1                    NaN      4.0     0.0      10114        64.0       5.0   \n",
       "2                    NaN      4.0     0.0         81         0.6       8.0   \n",
       "3                    NaN      6.0     0.0      10030        37.1      23.0   \n",
       "4                    NaN      8.0     0.0      10740        40.4      21.0   \n",
       "\n",
       "   initial_list_status  collections_12_mths_ex_med  \\\n",
       "0                    f                         0.0   \n",
       "1                    f                         0.0   \n",
       "2                    f                         0.0   \n",
       "3                    f                         0.0   \n",
       "4                    f                         0.0   \n",
       "\n",
       "   mths_since_last_major_derog  policy_code  \n",
       "0                            1          PC4  \n",
       "1                            2          PC1  \n",
       "2                            3          PC4  \n",
       "3                            2          PC2  \n",
       "4                            3          PC3  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load csv\n",
    "df_raw = pd.read_csv('dataset.csv')\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5593920",
   "metadata": {},
   "source": [
    "### Drop Unnecessary Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b110e6b",
   "metadata": {},
   "source": [
    "After quick observation, we can drop these columns from ```df_raw```:\n",
    "- ```Id```: contains no information other than index\n",
    "- ```Notes```: contains text data that is redundant with ```purpose_cat``` and other columns. Also has more than 3000 null entries\n",
    "- ```purpose```: redundant with ```purpose_cat```, also text data\n",
    "- ```collections_12_mths_ex_med```: contains mostly 0 or nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11eb2ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_bad</th>\n",
       "      <th>emp_title</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>pymnt_plan</th>\n",
       "      <th>purpose_cat</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>addr_state</th>\n",
       "      <th>...</th>\n",
       "      <th>mths_since_last_delinq</th>\n",
       "      <th>mths_since_last_record</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_acc</th>\n",
       "      <th>initial_list_status</th>\n",
       "      <th>mths_since_last_major_derog</th>\n",
       "      <th>policy_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Time Warner Cable</td>\n",
       "      <td>10</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>not verified</td>\n",
       "      <td>n</td>\n",
       "      <td>medical</td>\n",
       "      <td>766xx</td>\n",
       "      <td>TX</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12087</td>\n",
       "      <td>12.1</td>\n",
       "      <td>44.0</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>PC4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ottawa University</td>\n",
       "      <td>1</td>\n",
       "      <td>RENT</td>\n",
       "      <td>39216.0</td>\n",
       "      <td>not verified</td>\n",
       "      <td>n</td>\n",
       "      <td>debt consolidation</td>\n",
       "      <td>660xx</td>\n",
       "      <td>KS</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10114</td>\n",
       "      <td>64.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>f</td>\n",
       "      <td>2</td>\n",
       "      <td>PC1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Kennedy Wilson</td>\n",
       "      <td>4</td>\n",
       "      <td>RENT</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>not verified</td>\n",
       "      <td>n</td>\n",
       "      <td>credit card</td>\n",
       "      <td>916xx</td>\n",
       "      <td>CA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81</td>\n",
       "      <td>0.6</td>\n",
       "      <td>8.0</td>\n",
       "      <td>f</td>\n",
       "      <td>3</td>\n",
       "      <td>PC4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>TOWN OF PLATTEKILL</td>\n",
       "      <td>10</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>57500.0</td>\n",
       "      <td>not verified</td>\n",
       "      <td>n</td>\n",
       "      <td>debt consolidation</td>\n",
       "      <td>124xx</td>\n",
       "      <td>NY</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10030</td>\n",
       "      <td>37.1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>f</td>\n",
       "      <td>2</td>\n",
       "      <td>PC2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Belmont Correctional</td>\n",
       "      <td>10</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>50004.0</td>\n",
       "      <td>VERIFIED - income</td>\n",
       "      <td>n</td>\n",
       "      <td>debt consolidation</td>\n",
       "      <td>439xx</td>\n",
       "      <td>OH</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10740</td>\n",
       "      <td>40.4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>f</td>\n",
       "      <td>3</td>\n",
       "      <td>PC3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_bad             emp_title emp_length home_ownership  annual_inc  \\\n",
       "0       0     Time Warner Cable         10       MORTGAGE     50000.0   \n",
       "1       0     Ottawa University          1           RENT     39216.0   \n",
       "2       0        Kennedy Wilson          4           RENT     65000.0   \n",
       "3       0    TOWN OF PLATTEKILL         10       MORTGAGE     57500.0   \n",
       "4       0  Belmont Correctional         10       MORTGAGE     50004.0   \n",
       "\n",
       "  verification_status pymnt_plan         purpose_cat zip_code addr_state  ...  \\\n",
       "0        not verified          n             medical    766xx         TX  ...   \n",
       "1        not verified          n  debt consolidation    660xx         KS  ...   \n",
       "2        not verified          n         credit card    916xx         CA  ...   \n",
       "3        not verified          n  debt consolidation    124xx         NY  ...   \n",
       "4   VERIFIED - income          n  debt consolidation    439xx         OH  ...   \n",
       "\n",
       "   mths_since_last_delinq  mths_since_last_record open_acc  pub_rec  \\\n",
       "0                     NaN                     NaN     15.0      0.0   \n",
       "1                     NaN                     NaN      4.0      0.0   \n",
       "2                     NaN                     NaN      4.0      0.0   \n",
       "3                    16.0                     NaN      6.0      0.0   \n",
       "4                     NaN                     NaN      8.0      0.0   \n",
       "\n",
       "   revol_bal  revol_util  total_acc  initial_list_status  \\\n",
       "0      12087        12.1       44.0                    f   \n",
       "1      10114        64.0        5.0                    f   \n",
       "2         81         0.6        8.0                    f   \n",
       "3      10030        37.1       23.0                    f   \n",
       "4      10740        40.4       21.0                    f   \n",
       "\n",
       "   mths_since_last_major_derog  policy_code  \n",
       "0                            1          PC4  \n",
       "1                            2          PC1  \n",
       "2                            3          PC4  \n",
       "3                            2          PC2  \n",
       "4                            3          PC3  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete the columns as described above\n",
    "cols_to_delete = ['Id','Notes','purpose','collections_12_mths_ex_med']\n",
    "df_raw.drop(cols_to_delete,axis=1,inplace=True)\n",
    "\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57596537",
   "metadata": {},
   "source": [
    "### Deal with Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a132f5",
   "metadata": {},
   "source": [
    "Check for missing values for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71985a7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_bad                            0\n",
       "emp_title                       592\n",
       "emp_length                        0\n",
       "home_ownership                    0\n",
       "annual_inc                        1\n",
       "verification_status               0\n",
       "pymnt_plan                        0\n",
       "purpose_cat                       0\n",
       "zip_code                          0\n",
       "addr_state                        0\n",
       "debt_to_income                    0\n",
       "delinq_2yrs                       5\n",
       "earliest_cr_line                  5\n",
       "inq_last_6mths                    5\n",
       "mths_since_last_delinq         6316\n",
       "mths_since_last_record         9160\n",
       "open_acc                          5\n",
       "pub_rec                           5\n",
       "revol_bal                         0\n",
       "revol_util                       26\n",
       "total_acc                         5\n",
       "initial_list_status               0\n",
       "mths_since_last_major_derog       0\n",
       "policy_code                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6b1cac",
   "metadata": {},
   "source": [
    "We see that there are more than 5000 null entries for columns ```mths_since_last_delinq``` (Months since last delinquency) and ```mths_since_last_record``` (Months since last record)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fc19b7",
   "metadata": {},
   "source": [
    "Assuming that null values on these columns mean that the person either has no delinquency or record, I think it'll be reasonable to change the null values to the max value for that column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9292c93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the null values for 'mths_since_last_delinq' and 'mths_since_last_record' columns\n",
    "df_raw[\"mths_since_last_delinq\"].fillna(df_raw['mths_since_last_delinq'].max(), inplace = True)\n",
    "df_raw[\"mths_since_last_record\"].fillna(df_raw['mths_since_last_record'].max(), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64333c34",
   "metadata": {},
   "source": [
    "For the rest, drop the rows with null entries as they're only about 6% of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe932584",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e6705c",
   "metadata": {},
   "source": [
    "Check for null values again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "679b0036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_bad                         0\n",
       "emp_title                      0\n",
       "emp_length                     0\n",
       "home_ownership                 0\n",
       "annual_inc                     0\n",
       "verification_status            0\n",
       "pymnt_plan                     0\n",
       "purpose_cat                    0\n",
       "zip_code                       0\n",
       "addr_state                     0\n",
       "debt_to_income                 0\n",
       "delinq_2yrs                    0\n",
       "earliest_cr_line               0\n",
       "inq_last_6mths                 0\n",
       "mths_since_last_delinq         0\n",
       "mths_since_last_record         0\n",
       "open_acc                       0\n",
       "pub_rec                        0\n",
       "revol_bal                      0\n",
       "revol_util                     0\n",
       "total_acc                      0\n",
       "initial_list_status            0\n",
       "mths_since_last_major_derog    0\n",
       "policy_code                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19870262",
   "metadata": {},
   "source": [
    "### Miscellaneous"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa2fec9",
   "metadata": {},
   "source": [
    "I want to check for unique values for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53a46da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_bad unique values: [0 1]\n",
      "\n",
      "emp_title unique values: ['Time Warner Cable' 'Ottawa University' 'Kennedy Wilson' ...\n",
      " 'Weichert, Realtors' 'meadwestvaco' 'Rehab Alliance']\n",
      "\n",
      "emp_length unique values: ['10' '1' '4' '6' '2' '5' '3' '8' '7' '9' '22' '11' '33' 'na']\n",
      "\n",
      "home_ownership unique values: ['MORTGAGE' 'RENT' 'OWN' 'OTHER']\n",
      "\n",
      "annual_inc unique values: [50000. 39216. 65000. ... 66250. 47831. 70560.]\n",
      "\n",
      "verification_status unique values: ['not verified' 'VERIFIED - income' 'VERIFIED - income source']\n",
      "\n",
      "pymnt_plan unique values: ['n' 'y']\n",
      "\n",
      "purpose_cat unique values: ['medical' 'debt consolidation' 'credit card' 'other' 'wedding' 'house'\n",
      " 'small business' 'educational' 'major purchase' 'car' 'home improvement'\n",
      " 'vacation' 'other small business' 'debt consolidation small business'\n",
      " 'moving' 'credit card small business' 'wedding small business'\n",
      " 'small business small business' 'home improvement small business'\n",
      " 'educational small business' 'house small business' 'renewable energy'\n",
      " 'major purchase small business' 'moving small business'\n",
      " 'medical small business' 'vacation small business' 'car small business']\n",
      "\n",
      "zip_code unique values: ['766xx' '660xx' '916xx' '124xx' '439xx' '200xx' '103xx' '891xx' '612xx'\n",
      " '980xx' '198xx' '920xx' '604xx' '076xx' '925xx' '606xx' '741xx' '234xx'\n",
      " '908xx' '324xx' '038xx' '236xx' '142xx' '010xx' '614xx' '918xx' '287xx'\n",
      " '972xx' '304xx' '232xx' '802xx' '932xx' '070xx' '088xx' '210xx' '060xx'\n",
      " '633xx' '978xx' '535xx' '335xx' '857xx' '115xx' '104xx' '207xx' '272xx'\n",
      " '913xx' '951xx' '774xx' '221xx' '954xx' '971xx' '554xx' '453xx' '483xx'\n",
      " '188xx' '601xx' '790xx' '995xx' '275xx' '333xx' '720xx' '100xx' '787xx'\n",
      " '791xx' '330xx' '334xx' '700xx' '209xx' '958xx' '930xx' '331xx' '760xx'\n",
      " '297xx' '201xx' '309xx' '208xx' '306xx' '432xx' '173xx' '946xx' '223xx'\n",
      " '551xx' '984xx' '296xx' '080xx' '952xx' '170xx' '310xx' '021xx' '982xx'\n",
      " '013xx' '967xx' '455xx' '852xx' '301xx' '903xx' '752xx' '806xx' '481xx'\n",
      " '856xx' '144xx' '063xx' '773xx' '799xx' '761xx' '662xx' '600xx' '440xx'\n",
      " '402xx' '112xx' '900xx' '782xx' '605xx' '762xx' '706xx' '703xx' '302xx'\n",
      " '181xx' '945xx' '286xx' '922xx' '268xx' '750xx' '775xx' '029xx' '024xx'\n",
      " '935xx' '111xx' '941xx' '785xx' '105xx' '631xx' '917xx' '997xx' '347xx'\n",
      " '246xx' '231xx' '902xx' '926xx' '921xx' '077xx' '113xx' '067xx' '320xx'\n",
      " '106xx' '350xx' '712xx' '454xx' '295xx' '290xx' '083xx' '928xx' '352xx'\n",
      " '480xx' '968xx' '566xx' '735xx' '730xx' '068xx' '238xx' '241xx' '919xx'\n",
      " '609xx' '303xx' '553xx' '064xx' '336xx' '014xx' '543xx' '648xx' '801xx'\n",
      " '950xx' '177xx' '146xx' '219xx' '488xx' '140xx' '211xx' '906xx' '273xx'\n",
      " '658xx' '085xx' '983xx' '421xx' '087xx' '795xx' '127xx' '018xx' '030xx'\n",
      " '117xx' '235xx' '244xx' '548xx' '437xx' '356xx' '557xx' '128xx' '065xx'\n",
      " '074xx' '863xx' '570xx' '152xx' '110xx' '988xx' '180xx' '837xx' '711xx'\n",
      " '329xx' '299xx' '765xx' '923xx' '325xx' '933xx' '245xx' '724xx' '959xx'\n",
      " '770xx' '800xx' '940xx' '130xx' '756xx' '905xx' '194xx' '934xx' '550xx'\n",
      " '300xx' '990xx' '341xx' '278xx' '726xx' '846xx' '346xx' '705xx' '114xx'\n",
      " '721xx' '444xx' '212xx' '337xx' '442xx' '326xx' '641xx' '992xx' '571xx'\n",
      " '914xx' '815xx' '216xx' '280xx' '400xx' '011xx' '079xx' '974xx' '452xx'\n",
      " '406xx' '125xx' '164xx' '328xx' '199xx' '081xx' '260xx' '228xx' '598xx'\n",
      " '189xx' '023xx' '071xx' '158xx' '237xx' '129xx' '540xx' '850xx' '230xx'\n",
      " '086xx' '358xx' '066xx' '716xx' '376xx' '559xx' '853xx' '981xx' '890xx'\n",
      " '191xx' '731xx' '283xx' '217xx' '403xx' '171xx' '206xx' '652xx' '613xx'\n",
      " '748xx' '441xx' '498xx' '430xx' '327xx' '985xx' '953xx' '820xx' '174xx'\n",
      " '082xx' '960xx' '646xx' '957xx' '907xx' '120xx' '532xx' '360xx' '486xx'\n",
      " '542xx' '226xx' '841xx' '824xx' '546xx' '028xx' '468xx' '622xx' '490xx'\n",
      " '020xx' '956xx' '222xx' '840xx' '825xx' '482xx' '254xx' '314xx' '317xx'\n",
      " '751xx' '101xx' '218xx' '276xx' '410xx' '620xx' '119xx' '740xx' '947xx'\n",
      " '927xx' '626xx' '193xx' '131xx' '339xx' '996xx' '398xx' '025xx' '495xx'\n",
      " '456xx' '261xx' '053xx' '316xx' '359xx' '233xx' '279xx' '783xx' '948xx'\n",
      " '357xx' '190xx' '322xx' '534xx' '871xx' '811xx' '282xx' '611xx' '701xx'\n",
      " '109xx' '450xx' '342xx' '108xx' '313xx' '425xx' '075xx' '707xx' '220xx'\n",
      " '804xx' '292xx' '780xx' '323xx' '831xx' '031xx' '549xx' '354xx' '975xx'\n",
      " '619xx' '936xx' '404xx' '037xx' '229xx' '895xx' '847xx' '991xx' '737xx'\n",
      " '931xx' '851xx' '349xx' '608xx' '484xx' '073xx' '243xx' '153xx' '986xx'\n",
      " '786xx' '176xx' '563xx' '122xx' '915xx' '763xx' '657xx' '663xx' '970xx'\n",
      " '061xx' '150xx' '185xx' '242xx' '538xx' '027xx' '805xx' '640xx' '955xx'\n",
      " '939xx' '911xx' '308xx' '017xx' '949xx' '494xx' '610xx' '381xx' '910xx'\n",
      " '436xx' '294xx' '489xx' '015xx' '617xx' '541xx' '560xx' '240xx' '016xx'\n",
      " '904xx' '592xx' '284xx' '777xx' '797xx' '121xx' '722xx' '116xx' '136xx'\n",
      " '145xx' '107xx' '629xx' '338xx' '197xx' '305xx' '754xx' '492xx' '708xx'\n",
      " '019xx' '630xx' '912xx' '809xx' '496xx' '344xx' '875xx' '434xx' '759xx'\n",
      " '253xx' '645xx' '977xx' '184xx' '195xx' '672xx' '365xx' '154xx' '032xx'\n",
      " '050xx' '133xx' '054xx' '285xx' '591xx' '362xx' '530xx' '163xx' '259xx'\n",
      " '497xx' '351xx' '321xx' '147xx' '973xx' '500xx' '293xx' '062xx' '602xx'\n",
      " '435xx' '291xx' '445xx' '431xx' '998xx' '371xx' '894xx' '424xx' '577xx'\n",
      " '597xx' '448xx' '665xx' '281xx' '784xx' '370xx' '137xx' '674xx' '937xx'\n",
      " '161xx' '368xx' '628xx' '897xx' '149xx' '625xx' '363xx' '884xx' '893xx'\n",
      " '829xx' '394xx' '182xx' '880xx' '026xx' '274xx' '813xx' '405xx' '157xx'\n",
      " '271xx' '704xx' '764xx' '089xx' '676xx' '224xx' '265xx' '944xx' '539xx'\n",
      " '655xx' '451xx' '132xx' '433xx' '165xx' '993xx' '225xx' '745xx' '670xx'\n",
      " '757xx' '828xx' '961xx' '315xx' '816xx' '364xx' '624xx' '447xx' '187xx'\n",
      " '160xx' '078xx' '594xx' '767xx' '723xx' '727xx' '134xx' '148xx' '531xx'\n",
      " '493xx' '729xx' '264xx' '318xx' '179xx' '882xx' '141xx' '458xx' '361xx'\n",
      " '744xx' '661xx' '457xx' '178xx' '443xx' '562xx' '183xx' '685xx' '257xx'\n",
      " '830xx' '634xx' '943xx' '976xx' '607xx' '252xx' '793xx' '668xx' '126xx'\n",
      " '118xx' '262xx' '366xx' '803xx' '810xx' '175xx' '123xx' '446xx' '215xx'\n",
      " '778xx' '156xx' '713xx' '166xx' '547xx' '596xx' '491xx' '599xx' '864xx'\n",
      " '379xx' '072xx' '135xx' '355xx' '186xx' '808xx' '270xx' '397xx' '084xx'\n",
      " '277xx' '618xx' '544xx' '056xx' '255xx' '307xx' '319xx' '860xx' '407xx'\n",
      " '409xx' '258xx' '666xx' '251xx' '469xx' '057xx' '034xx' '035xx' '565xx'\n",
      " '739xx' '168xx' '650xx' '196xx' '877xx' '138xx' '401xx' '749xx' '412xx'\n",
      " '151xx' '656xx' '069xx' '969xx' '989xx' '603xx' '627xx' '788xx' '669xx'\n",
      " '781xx' '796xx' '527xx' '827xx' '636xx' '420xx' '651xx' '388xx' '288xx'\n",
      " '874xx' '653xx' '479xx' '673xx' '499xx' '139xx' '247xx' '537xx' '678xx'\n",
      " '256xx' '392xx' '717xx' '167xx' '012xx' '395xx' '836xx' '714xx' '681xx'\n",
      " '102xx' '883xx' '227xx' '411xx' '667xx' '638xx' '572xx' '647xx' '471xx'\n",
      " '312xx' '826xx' '558xx' '794xx' '462xx' '385xx' '214xx' '298xx' '423xx'\n",
      " '390xx' '041xx' '415xx' '768xx' '843xx' '728xx' '743xx' '427xx' '051xx'\n",
      " '798xx' '616xx' '593xx' '710xx' '664xx' '545xx' '639xx' '266xx' '007xx'\n",
      " '719xx' '637xx']\n",
      "\n",
      "addr_state unique values: ['TX' 'KS' 'CA' 'NY' 'OH' 'DC' 'NV' 'IL' 'WA' 'DE' 'NJ' 'OK' 'VA' 'FL'\n",
      " 'NH' 'MA' 'NC' 'OR' 'GA' 'CO' 'MD' 'CT' 'MO' 'WI' 'AZ' 'SC' 'MN' 'MI'\n",
      " 'PA' 'AK' 'AR' 'LA' 'HI' 'KY' 'WV' 'RI' 'AL' 'SD' 'ID' 'UT' 'MT' 'WY'\n",
      " 'VT' 'NM' 'TN' 'IA' 'NE' 'MS' 'IN' 'ME']\n",
      "\n",
      "debt_to_income unique values: [10.87  9.15 11.24 ... 24.74 20.91 24.13]\n",
      "\n",
      "delinq_2yrs unique values: [ 0.  1.  2.  4.  3.  7.  6.  5. 11.  8.]\n",
      "\n",
      "earliest_cr_line unique values: ['12/01/1992' '11/01/2005' '06/01/1970' '09/01/1982' '10/01/1999'\n",
      " '12/01/1999' '11/01/1979' '04/01/2006' '02/01/2001' '06/01/1993'\n",
      " '04/01/1996' '10/01/1996' '01/01/1993' '01/01/2003' '11/01/1999'\n",
      " '12/01/1996' '11/01/1997' '09/01/1994' '06/01/1995' '03/01/1987'\n",
      " '01/01/1999' '02/01/2000' '05/01/2000' '07/01/2005' '04/01/1994'\n",
      " '07/01/1995' '10/01/2001' '06/01/1997' '10/01/2000' '08/01/2003'\n",
      " '02/01/1996' '10/01/2004' '08/01/1998' '07/01/2001' '01/01/2004'\n",
      " '02/01/1995' '09/01/2001' '02/01/2007' '08/01/1997' '03/01/2000'\n",
      " '09/01/1992' '10/01/1995' '01/01/2000' '01/01/1987' '01/01/2001'\n",
      " '09/01/1984' '07/01/1986' '01/01/2006' '07/01/1980' '12/01/1998'\n",
      " '09/01/2004' '04/01/2000' '06/01/1976' '05/01/2004' '08/01/1999'\n",
      " '03/01/1981' '03/01/2001' '09/01/2002' '07/01/1997' '03/01/2005'\n",
      " '11/01/1995' '02/01/2006' '12/01/2002' '07/01/2007' '08/01/2002'\n",
      " '04/01/1984' '05/01/1988' '12/01/2003' '02/01/1997' '08/01/1995'\n",
      " '05/01/1998' '03/01/1982' '10/01/2005' '07/01/2002' '01/01/1989'\n",
      " '12/01/1995' '06/01/2001' '07/01/2006' '08/01/1991' '10/01/1992'\n",
      " '02/01/1983' '08/01/1990' '10/01/1990' '04/01/2004' '05/01/2001'\n",
      " '05/01/1997' '07/01/2000' '06/01/1996' '05/01/1978' '05/01/2003'\n",
      " '02/01/1998' '01/01/1994' '01/01/1996' '08/01/1987' '08/01/1985'\n",
      " '01/01/1988' '06/01/1985' '01/01/2005' '09/01/1999' '03/01/1999'\n",
      " '07/01/1991' '05/01/1995' '08/01/2000' '09/01/1986' '09/01/1990'\n",
      " '08/01/1984' '04/01/2005' '09/01/1985' '02/01/2002' '04/01/2002'\n",
      " '12/01/2000' '03/01/1997' '06/01/2000' '11/01/1994' '11/01/1984'\n",
      " '01/01/1997' '11/01/1983' '10/01/1986' '07/01/2004' '02/01/1970'\n",
      " '11/01/1998' '11/01/2000' '04/01/1993' '03/01/2006' '10/01/1994'\n",
      " '04/01/1997' '03/01/1986' '03/01/1994' '04/01/1971' '09/01/1989'\n",
      " '01/01/1998' '08/01/2001' '12/01/1989' '03/01/1990' '10/01/1998'\n",
      " '08/01/1979' '01/01/1991' '10/01/2003' '10/01/1993' '04/01/1990'\n",
      " '05/01/2005' '07/01/1987' '03/01/2004' '05/01/1992' '06/01/1994'\n",
      " '08/01/1992' '12/01/1994' '03/01/1998' '03/01/1970' '04/01/1982'\n",
      " '09/01/1996' '12/01/2001' '06/01/2003' '03/01/2003' '11/01/1996'\n",
      " '02/01/1994' '01/01/2007' '10/01/1991' '02/01/2005' '04/01/1999'\n",
      " '01/01/1992' '11/01/1993' '07/01/1998' '09/01/2003' '11/01/1990'\n",
      " '06/01/1998' '09/01/2006' '09/01/1997' '12/01/1987' '09/01/2000'\n",
      " '08/01/2005' '07/01/1992' '07/01/1996' '09/01/2005' '04/01/1995'\n",
      " '12/01/1990' '11/01/1988' '04/01/2007' '12/01/1997' '12/01/1982'\n",
      " '10/01/1997' '06/01/2004' '09/01/1980' '09/01/1995' '05/01/1999'\n",
      " '03/01/1992' '06/01/1991' '05/01/1996' '06/01/2006' '07/01/1990'\n",
      " '10/01/2002' '11/01/1986' '08/01/1982' '05/01/1994' '07/01/1994'\n",
      " '04/01/2001' '05/01/1993' '07/01/2003' '05/01/1984' '11/01/2001'\n",
      " '11/01/1991' '11/01/2003' '08/01/1994' '04/01/1991' '12/01/2004'\n",
      " '11/01/2002' '02/01/2008' '11/01/2008' '06/01/1987' '05/01/1991'\n",
      " '11/01/2004' '12/01/2006' '03/01/2008' '06/01/1981' '01/01/1984'\n",
      " '08/01/1996' '03/01/1995' '12/01/1986' '08/01/1989' '02/01/1992'\n",
      " '06/01/1999' '08/01/2007' '06/01/1986' '04/01/2008' '12/01/1993'\n",
      " '06/01/1982' '11/01/1985' '02/01/1993' '10/01/1982' '07/01/1999'\n",
      " '06/01/2007' '10/01/1989' '01/01/1995' '11/01/2006' '06/01/2005'\n",
      " '01/01/2002' '01/01/1986' '06/01/2002' '12/01/1988' '02/01/1989'\n",
      " '03/01/1974' '02/01/2003' '06/01/1984' '11/01/1989' '08/01/2006'\n",
      " '02/01/1990' '08/01/1977' '09/01/1991' '04/01/1988' '12/01/2005'\n",
      " '02/01/1985' '03/01/1996' '09/01/1962' '02/01/1982' '11/01/2007'\n",
      " '02/01/2004' '12/01/1974' '05/01/2007' '05/01/2006' '04/01/1989'\n",
      " '07/01/1977' '04/01/1983' '06/01/1990' '02/01/1991' '02/01/1999'\n",
      " '10/01/1971' '10/01/1979' '01/01/1990' '09/01/2007' '09/01/1998'\n",
      " '05/01/1990' '04/01/1981' '08/01/2004' '03/01/1989' '06/01/1988'\n",
      " '05/01/1987' '11/01/1992' '06/01/1992' '12/01/1973' '08/01/1993'\n",
      " '04/01/2003' '03/01/2007' '09/01/1988' '10/01/1977' '03/01/1979'\n",
      " '03/01/2002' '10/01/1987' '07/01/1993' '05/01/2002' '08/01/1988'\n",
      " '03/01/1984' '02/01/1986' '09/01/1981' '03/01/1983' '04/01/1985'\n",
      " '09/01/1993' '05/01/1979' '10/01/2006' '04/01/1992' '07/01/1989'\n",
      " '08/01/1980' '07/01/1978' '10/01/1984' '05/01/2008' '04/01/1986'\n",
      " '09/01/1979' '06/01/2008' '04/01/1998' '01/01/1979' '05/01/1980'\n",
      " '05/01/1983' '03/01/1985' '09/01/1978' '10/01/2007' '02/01/1987'\n",
      " '12/01/1984' '03/01/1978' '08/01/1969' '07/01/1988' '10/01/1988'\n",
      " '10/01/1983' '08/01/1978' '06/01/1980' '12/01/1983' '03/01/1993'\n",
      " '06/01/1977' '11/01/1978' '03/01/1991' '05/01/1982' '02/01/1988'\n",
      " '10/01/1985' '03/01/1975' '04/01/1987' '02/01/1984' '07/01/1983'\n",
      " '08/01/1986' '09/01/1987' '12/01/1980' '01/01/1981' '12/01/1976'\n",
      " '09/01/1972' '01/01/1980' '10/01/1981' '07/01/1985' '01/01/1968'\n",
      " '12/01/1985' '05/01/1989' '12/01/2007' '07/01/1975' '11/01/1975'\n",
      " '01/01/2008' '06/01/1989' '11/01/1976' '08/01/1981' '09/01/1983'\n",
      " '11/01/1987' '07/01/1984' '10/01/1980' '08/01/1973' '01/01/1982'\n",
      " '01/01/1972' '02/01/1976' '06/01/1971' '04/01/1976' '12/01/1991'\n",
      " '06/01/1974' '08/01/1976' '07/01/1982' '08/01/1983' '06/01/1983'\n",
      " '05/01/1974' '03/01/1988' '03/01/1977' '12/01/1979' '11/01/1969'\n",
      " '04/01/1979' '08/01/1974' '05/01/1965' '05/01/1985' '10/01/1976'\n",
      " '02/01/1979' '01/01/1977' '03/01/1972' '07/01/1973' '05/01/1973'\n",
      " '07/01/1967' '01/01/1983' '04/01/1977' '02/01/1981' '04/01/1967'\n",
      " '09/01/1967' '12/01/1968' '01/01/1985' '08/01/2008' '12/01/1950'\n",
      " '09/01/1976' '08/01/1970' '11/01/1982' '05/01/1981' '04/01/1975'\n",
      " '06/01/1967' '05/01/1977' '11/01/1971' '04/01/1978' '12/01/1975'\n",
      " '07/01/1976' '05/01/1986' '09/01/1973' '01/01/1973' '12/01/1970'\n",
      " '03/01/1969' '09/01/1970' '12/01/1978' '05/01/1970' '01/01/1975'\n",
      " '07/01/1972' '09/01/1963' '01/01/1978' '03/01/1980' '10/01/1973'\n",
      " '09/01/1956' '09/01/2008' '02/01/1980' '07/01/1974' '05/01/1976'\n",
      " '07/01/1979' '06/01/1979' '06/01/1978' '11/01/1981' '03/01/1971'\n",
      " '01/01/1963' '08/01/1968' '05/01/1969' '12/01/1966' '12/01/1977'\n",
      " '10/01/1978' '12/01/1981' '02/01/1974' '02/01/1975' '01/01/1976'\n",
      " '08/01/1975' '06/01/1973' '10/01/1972' '07/01/1981' '12/01/1972'\n",
      " '02/01/1971' '07/01/1971' '07/01/2008']\n",
      "\n",
      "inq_last_6mths unique values: [ 0.  2.  4.  1.  3.  6.  8.  5.  7. 16.  9. 18. 10. 25. 11. 17. 15. 24.\n",
      " 14. 12.]\n",
      "\n",
      "mths_since_last_delinq unique values: [120.  16.  19.  13.  34.  49.  32.  67.  48.  58.  52.  39.  60.  62.\n",
      "  64.   4.  63.  27.  15.  11.  26.   9.  23.  31.  55.  17.  42.  44.\n",
      "  78.  38.  54.  41.  28.  56.   6.  37.   5.  36.  81.  47.  18.  82.\n",
      "  79.  69.  22.  76.  24.  73.   0.  29.  33.  61.  12.  43.   3.   8.\n",
      "  72.  70.  20.  68.  59.  80.  30.  46.  21.  14.  25.  10.  66.  57.\n",
      "  35.  65.  53.  71.  51.   2.  50.   7.  45.  74.  77.  75. 115.   1.\n",
      "  40.  97.  95.  83.  85.  89.  96.]\n",
      "\n",
      "mths_since_last_record unique values: [119.  27.  92.   0.  88.  98. 113. 110.  93. 101.  77.  63.  38. 116.\n",
      "  56.  95.  68.  96.  72. 100. 102. 104. 107.  91.  89.  53.  59.  41.\n",
      "  94. 112. 115.  85. 111.  47.  90.  86. 109.  48. 114.  20. 108. 106.\n",
      "  50.  67.  81.  74.  49.  30. 103.  87.  99. 105.  66.  71.  45. 118.\n",
      "  44.  25.  62.  58. 117.  78.  51.   6.  76.  80.  55.  40.  97.  61.\n",
      "  26.  29.  73.  46.  65.  31.  60.  33.  57.  17.  70.  36.  52.  54.\n",
      "  75.  69.  11.  39.  43.  28.  64.  82.  24.]\n",
      "\n",
      "open_acc unique values: [15.  4.  6.  8. 18.  9. 11. 12.  3. 13.  5. 16. 10.  2. 14.  7. 25. 19.\n",
      " 30. 17. 20. 21. 29. 26. 24. 22. 23. 28. 36.  1. 39. 33. 27. 31. 32.]\n",
      "\n",
      "pub_rec unique values: [0. 1. 2. 3.]\n",
      "\n",
      "revol_bal unique values: [12087 10114    81 ... 11346 17157  2304]\n",
      "\n",
      "revol_util unique values: [1.210e+01 6.400e+01 6.000e-01 ... 3.688e+01 3.000e-02 1.006e+02]\n",
      "\n",
      "total_acc unique values: [44.  5.  8. 23. 21. 25. 29. 10. 27. 24. 37. 19. 36. 54. 20. 26.  7. 22.\n",
      " 13. 12. 16. 18. 43. 38. 49. 15. 31. 11.  3. 32. 28. 30. 56. 39. 17. 35.\n",
      "  9. 34.  6. 62. 14. 33. 41. 61. 46.  4. 50. 47. 55. 42. 63. 52. 40. 66.\n",
      " 57. 48. 45. 53.  1. 51.  2. 60. 67. 90. 58. 78. 59. 77. 80. 70. 64. 79.\n",
      " 69. 81.]\n",
      "\n",
      "initial_list_status unique values: ['f' 'm']\n",
      "\n",
      "mths_since_last_major_derog unique values: [1 2 3]\n",
      "\n",
      "policy_code unique values: ['PC4' 'PC1' 'PC2' 'PC3' 'PC5']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in df_raw.columns:\n",
    "    print(f'{col} unique values: {df_raw[col].unique()}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0e95cf",
   "metadata": {},
   "source": [
    "We note few things: \n",
    "- ```emp_length``` values are strings when they should be ints (or floats). There are also 'na' entries.\n",
    "- ```earliest_cr_line``` values are strings when we want them to be some type of numerical values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e930f9d",
   "metadata": {},
   "source": [
    "Convert ```emp_length``` by turning it into int values. We assume that 'na' entries correspond to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c750517a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw['emp_length'] = df_raw['emp_length'].apply(lambda x: 0 if x=='na' else int(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421c3acc",
   "metadata": {},
   "source": [
    "Convert ```earliest_cr_line``` into integer timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e9b411d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw['earliest_cr_line'] = pd.to_datetime(df_raw['earliest_cr_line']).astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8238787",
   "metadata": {},
   "source": [
    "Reset the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdd74505",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = df_raw.reset_index()\n",
    "df_raw.drop(['index'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91af247c",
   "metadata": {},
   "source": [
    "### ```StandardScaler``` for numerical columns and ```OneHotEncoder``` for categorical (nominal) columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946539af",
   "metadata": {},
   "source": [
    "Only these two since we don't have ordinal categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7533e18",
   "metadata": {},
   "source": [
    "First let's divide the columns into 3 categories:\n",
    "- ```target```\n",
    "- ```numerical```\n",
    "- ```categorical```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29846c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = ['is_bad']\n",
    "numerical = ['emp_length', 'annual_inc', 'debt_to_income', 'delinq_2yrs',\n",
    "             'earliest_cr_line', 'inq_last_6mths', 'mths_since_last_delinq',\n",
    "             'mths_since_last_record', 'open_acc', 'pub_rec', 'revol_bal',\n",
    "             'revol_util', 'total_acc', 'mths_since_last_major_derog']\n",
    "categorical = ['emp_title', 'home_ownership', 'verification_status', 'pymnt_plan',\n",
    "               'purpose_cat', 'zip_code', 'addr_state', 'initial_list_status',\n",
    "               'policy_code']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4009da",
   "metadata": {},
   "source": [
    "Make intermediate ```df_target```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "375446ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target = pd.DataFrame(df_raw[target].values,columns=target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b257016",
   "metadata": {},
   "source": [
    "Make intermediate ```df_numerical```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86cef295",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emp_length</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>debt_to_income</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>earliest_cr_line</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>mths_since_last_delinq</th>\n",
       "      <th>mths_since_last_record</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_acc</th>\n",
       "      <th>mths_since_last_major_derog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.447377</td>\n",
       "      <td>-0.384031</td>\n",
       "      <td>-0.381719</td>\n",
       "      <td>-0.295756</td>\n",
       "      <td>-0.665415</td>\n",
       "      <td>-0.719764</td>\n",
       "      <td>0.728143</td>\n",
       "      <td>0.230337</td>\n",
       "      <td>1.238614</td>\n",
       "      <td>-0.235839</td>\n",
       "      <td>-0.089629</td>\n",
       "      <td>-1.302304</td>\n",
       "      <td>1.876884</td>\n",
       "      <td>-1.240396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.166366</td>\n",
       "      <td>-0.607497</td>\n",
       "      <td>-0.637186</td>\n",
       "      <td>-0.295756</td>\n",
       "      <td>1.285905</td>\n",
       "      <td>0.631124</td>\n",
       "      <td>0.728143</td>\n",
       "      <td>0.230337</td>\n",
       "      <td>-1.194044</td>\n",
       "      <td>-0.235839</td>\n",
       "      <td>-0.168193</td>\n",
       "      <td>0.541755</td>\n",
       "      <td>-1.466361</td>\n",
       "      <td>-0.005263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.295118</td>\n",
       "      <td>-0.073202</td>\n",
       "      <td>-0.326763</td>\n",
       "      <td>-0.295756</td>\n",
       "      <td>-4.064714</td>\n",
       "      <td>-0.719764</td>\n",
       "      <td>0.728143</td>\n",
       "      <td>0.230337</td>\n",
       "      <td>-1.194044</td>\n",
       "      <td>-0.235839</td>\n",
       "      <td>-0.567702</td>\n",
       "      <td>-1.710911</td>\n",
       "      <td>-1.209188</td>\n",
       "      <td>1.229871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.447377</td>\n",
       "      <td>-0.228617</td>\n",
       "      <td>-1.078314</td>\n",
       "      <td>1.663704</td>\n",
       "      <td>-2.213897</td>\n",
       "      <td>-0.719764</td>\n",
       "      <td>-1.699751</td>\n",
       "      <td>0.230337</td>\n",
       "      <td>-0.751743</td>\n",
       "      <td>-0.235839</td>\n",
       "      <td>-0.171537</td>\n",
       "      <td>-0.414029</td>\n",
       "      <td>0.076675</td>\n",
       "      <td>-0.005263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.447377</td>\n",
       "      <td>-0.383948</td>\n",
       "      <td>0.830267</td>\n",
       "      <td>-0.295756</td>\n",
       "      <td>0.366493</td>\n",
       "      <td>1.982012</td>\n",
       "      <td>0.728143</td>\n",
       "      <td>0.230337</td>\n",
       "      <td>-0.309441</td>\n",
       "      <td>-0.235839</td>\n",
       "      <td>-0.143266</td>\n",
       "      <td>-0.296777</td>\n",
       "      <td>-0.094773</td>\n",
       "      <td>1.229871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emp_length  annual_inc  debt_to_income  delinq_2yrs  earliest_cr_line  \\\n",
       "0    1.447377   -0.384031       -0.381719    -0.295756         -0.665415   \n",
       "1   -1.166366   -0.607497       -0.637186    -0.295756          1.285905   \n",
       "2   -0.295118   -0.073202       -0.326763    -0.295756         -4.064714   \n",
       "3    1.447377   -0.228617       -1.078314     1.663704         -2.213897   \n",
       "4    1.447377   -0.383948        0.830267    -0.295756          0.366493   \n",
       "\n",
       "   inq_last_6mths  mths_since_last_delinq  mths_since_last_record  open_acc  \\\n",
       "0       -0.719764                0.728143                0.230337  1.238614   \n",
       "1        0.631124                0.728143                0.230337 -1.194044   \n",
       "2       -0.719764                0.728143                0.230337 -1.194044   \n",
       "3       -0.719764               -1.699751                0.230337 -0.751743   \n",
       "4        1.982012                0.728143                0.230337 -0.309441   \n",
       "\n",
       "    pub_rec  revol_bal  revol_util  total_acc  mths_since_last_major_derog  \n",
       "0 -0.235839  -0.089629   -1.302304   1.876884                    -1.240396  \n",
       "1 -0.235839  -0.168193    0.541755  -1.466361                    -0.005263  \n",
       "2 -0.235839  -0.567702   -1.710911  -1.209188                     1.229871  \n",
       "3 -0.235839  -0.171537   -0.414029   0.076675                    -0.005263  \n",
       "4 -0.235839  -0.143266   -0.296777  -0.094773                     1.229871  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define standardscaler\n",
    "std = StandardScaler()\n",
    "\n",
    "df_numerical = pd.DataFrame(std.fit_transform(df_raw[numerical]),\n",
    "                            columns=numerical)\n",
    "\n",
    "df_numerical.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dc0548",
   "metadata": {},
   "source": [
    "Same for ```df_categorical```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a846a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emp_title_ U.S. Dept. Of Homeland Security</th>\n",
       "      <th>emp_title_(Collaborative) Abbott Nutrition Intl</th>\n",
       "      <th>emp_title_(self) Castleforte Group</th>\n",
       "      <th>emp_title_1)-Yavapai Regional Medical Center 2)- Dr. cantors office</th>\n",
       "      <th>emp_title_128 Air Refueling Wing (USAF)</th>\n",
       "      <th>emp_title_162 fighter wing</th>\n",
       "      <th>emp_title_19th Circuit State Attorney's Office</th>\n",
       "      <th>emp_title_1Life Healthcare</th>\n",
       "      <th>emp_title_1ST FRANKLIN FINANCIAL CORP</th>\n",
       "      <th>emp_title_1st Financial Bank</th>\n",
       "      <th>...</th>\n",
       "      <th>addr_state_VT</th>\n",
       "      <th>addr_state_WA</th>\n",
       "      <th>addr_state_WI</th>\n",
       "      <th>addr_state_WV</th>\n",
       "      <th>addr_state_WY</th>\n",
       "      <th>initial_list_status_m</th>\n",
       "      <th>policy_code_PC2</th>\n",
       "      <th>policy_code_PC3</th>\n",
       "      <th>policy_code_PC4</th>\n",
       "      <th>policy_code_PC5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8993 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   emp_title_ U.S. Dept. Of Homeland Security  \\\n",
       "0                                         0.0   \n",
       "1                                         0.0   \n",
       "2                                         0.0   \n",
       "3                                         0.0   \n",
       "4                                         0.0   \n",
       "\n",
       "   emp_title_(Collaborative) Abbott Nutrition Intl   \\\n",
       "0                                               0.0   \n",
       "1                                               0.0   \n",
       "2                                               0.0   \n",
       "3                                               0.0   \n",
       "4                                               0.0   \n",
       "\n",
       "   emp_title_(self) Castleforte Group  \\\n",
       "0                                 0.0   \n",
       "1                                 0.0   \n",
       "2                                 0.0   \n",
       "3                                 0.0   \n",
       "4                                 0.0   \n",
       "\n",
       "   emp_title_1)-Yavapai Regional Medical Center 2)- Dr. cantors office  \\\n",
       "0                                                0.0                     \n",
       "1                                                0.0                     \n",
       "2                                                0.0                     \n",
       "3                                                0.0                     \n",
       "4                                                0.0                     \n",
       "\n",
       "   emp_title_128 Air Refueling Wing (USAF)  emp_title_162 fighter wing  \\\n",
       "0                                      0.0                         0.0   \n",
       "1                                      0.0                         0.0   \n",
       "2                                      0.0                         0.0   \n",
       "3                                      0.0                         0.0   \n",
       "4                                      0.0                         0.0   \n",
       "\n",
       "   emp_title_19th Circuit State Attorney's Office  emp_title_1Life Healthcare  \\\n",
       "0                                             0.0                         0.0   \n",
       "1                                             0.0                         0.0   \n",
       "2                                             0.0                         0.0   \n",
       "3                                             0.0                         0.0   \n",
       "4                                             0.0                         0.0   \n",
       "\n",
       "   emp_title_1ST FRANKLIN FINANCIAL CORP   emp_title_1st Financial Bank  ...  \\\n",
       "0                                     0.0                           0.0  ...   \n",
       "1                                     0.0                           0.0  ...   \n",
       "2                                     0.0                           0.0  ...   \n",
       "3                                     0.0                           0.0  ...   \n",
       "4                                     0.0                           0.0  ...   \n",
       "\n",
       "   addr_state_VT  addr_state_WA  addr_state_WI  addr_state_WV  addr_state_WY  \\\n",
       "0            0.0            0.0            0.0            0.0            0.0   \n",
       "1            0.0            0.0            0.0            0.0            0.0   \n",
       "2            0.0            0.0            0.0            0.0            0.0   \n",
       "3            0.0            0.0            0.0            0.0            0.0   \n",
       "4            0.0            0.0            0.0            0.0            0.0   \n",
       "\n",
       "   initial_list_status_m  policy_code_PC2  policy_code_PC3  policy_code_PC4  \\\n",
       "0                    0.0              0.0              0.0              1.0   \n",
       "1                    0.0              0.0              0.0              0.0   \n",
       "2                    0.0              0.0              0.0              1.0   \n",
       "3                    0.0              1.0              0.0              0.0   \n",
       "4                    0.0              0.0              1.0              0.0   \n",
       "\n",
       "   policy_code_PC5  \n",
       "0              0.0  \n",
       "1              0.0  \n",
       "2              0.0  \n",
       "3              0.0  \n",
       "4              0.0  \n",
       "\n",
       "[5 rows x 8993 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define onehotencoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore',\n",
    "                    drop='first')\n",
    "\n",
    "df_categorical = pd.DataFrame(enc.fit_transform(df_raw[categorical]).toarray(),\n",
    "                              columns=enc.get_feature_names_out(categorical))\n",
    "\n",
    "df_categorical.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18597b5",
   "metadata": {},
   "source": [
    "### Define ```X```, ```y```, and Put Aside Holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3427f73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.concat([df_target,df_numerical,df_categorical],axis=1)\n",
    "\n",
    "X = df_combined.drop(['is_bad'],axis=1)\n",
    "y = df_combined['is_bad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e37b5ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_holdout, y, y_holdout = train_test_split(X, y, test_size=0.2, random_state=869255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5815903b",
   "metadata": {},
   "source": [
    "### Define CV Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "498d25a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "folds = StratifiedKFold(n_splits=n_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0540f9c8",
   "metadata": {},
   "source": [
    "# Prepare the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee56537e",
   "metadata": {},
   "source": [
    "For completeness, I'll use all three methods suggested in the task (logistic regression, GBM, and NN). However, due to computational cost, I will only do CV fold on the first two. For the NN, the model will only be tested on the holdout dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afcfb938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression \n",
    "LR = LogisticRegression(penalty='l2', max_iter=1000)\n",
    "\n",
    "# GBM\n",
    "# Parameter from documentation \n",
    "GBM = GradientBoostingClassifier(n_estimators=100, \n",
    "                                 learning_rate=1.0,\n",
    "                                 max_depth=1, \n",
    "                                 random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f35d57",
   "metadata": {},
   "source": [
    "Define CV fold function to train and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef78ca84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y, CVfold):\n",
    "    # Define metrics of the model\n",
    "    LL = np.zeros(CVfold.n_splits)\n",
    "    F1 = np.zeros(CVfold.n_splits)\n",
    "    accuracy = np.zeros(CVfold.n_splits)\n",
    "    \n",
    "    for i, (train, test) in enumerate(CVfold.split(X,y)):\n",
    "        print(f'CV {i+1} out of {CVfold.n_splits}')\n",
    "        \n",
    "        # Split X and y\n",
    "        X_train = X.iloc[train]\n",
    "        X_test = X.iloc[test]\n",
    "        y_train = y.iloc[train]\n",
    "        y_test = y.iloc[test]\n",
    "    \n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Get y_pred (predicted binary) y_pred_prob (predicted binary probability to be 1, hence [:,1])\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_prob = model.predict_proba(X_test)[:,1]\n",
    "        \n",
    "        # Get the stats\n",
    "        LL[i] = log_loss(y_test, y_pred_prob)\n",
    "        F1[i] = f1_score(y_test, y_pred)\n",
    "        accuracy[i] = model.score(X_test, y_test)\n",
    "        \n",
    "    return LL, F1, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9f5dff",
   "metadata": {},
   "source": [
    "Same for using the holdout dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6118f48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_holdout(model, X, y, X_holdout, y_holdout):\n",
    "    # Train the model\n",
    "    model.fit(X, y)\n",
    "\n",
    "    # Get y_pred (predicted binary) y_pred_prob (predicted binary probability to be 1, hence [:,1])\n",
    "    y_pred = model.predict(X_holdout)\n",
    "    y_pred_prob = model.predict_proba(X_holdout)[:,1]\n",
    "\n",
    "    # Get the stats\n",
    "    LL = log_loss(y_holdout, y_pred_prob)\n",
    "    F1 = f1_score(y_holdout, y_pred)\n",
    "    accuracy = model.score(X_holdout, y_holdout)\n",
    "        \n",
    "    return LL, F1, accuracy, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5102ef",
   "metadata": {},
   "source": [
    "# Train and Evaluate Logistic Regression and GBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d1909a",
   "metadata": {},
   "source": [
    "Evaluate two sklearn models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "622d9db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV 1 out of 5\n",
      "CV 2 out of 5\n",
      "CV 3 out of 5\n",
      "CV 4 out of 5\n",
      "CV 5 out of 5\n",
      "CV 1 out of 5\n",
      "CV 2 out of 5\n",
      "CV 3 out of 5\n",
      "CV 4 out of 5\n",
      "CV 5 out of 5\n"
     ]
    }
   ],
   "source": [
    "log_loss_LR, F1_LR, accuracy_LR = evaluate_model(model=LR,\n",
    "                                                 X=X,\n",
    "                                                 y=y,\n",
    "                                                 CVfold=folds)\n",
    "\n",
    "log_loss_GBM, F1_GBM, accuracy_GBM = evaluate_model(model=GBM,\n",
    "                                                   X=X,\n",
    "                                                   y=y,\n",
    "                                                   CVfold=folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "125c5aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression:\n",
      "Log loss mean: 0.34\n",
      "F1 score mean: 0.21\n",
      "Accuracy mean: 0.89\n",
      "\n",
      "Gradient boost machine:\n",
      "Log loss mean: 0.36\n",
      "F1 score mean: 0.24\n",
      "Accuracy mean: 0.89\n"
     ]
    }
   ],
   "source": [
    "print('Logistic regression:')\n",
    "print(f'Log loss mean: {np.mean(log_loss_LR):0.2f}')\n",
    "print(f'F1 score mean: {np.mean(F1_LR):0.2f}')\n",
    "print(f'Accuracy mean: {np.mean(accuracy_LR):0.2f}')\n",
    "print()\n",
    "print('Gradient boost machine:')\n",
    "print(f'Log loss mean: {np.mean(log_loss_GBM):0.2f}')\n",
    "print(f'F1 score mean: {np.mean(F1_GBM):0.2f}')\n",
    "print(f'Accuracy mean: {np.mean(accuracy_GBM):0.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a249ab",
   "metadata": {},
   "source": [
    "We see that logistic regression has lower loss but GBM has higher F1 score. Both have same accuracy score. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f562746e",
   "metadata": {},
   "source": [
    "Let's test the models on the holdout dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f442c923",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss_LR_holdout, F1_LR_holdout, accuracy_LR_holdout, y_pred_LR = \\\n",
    "evaluate_model_holdout(model=LR,\n",
    "                       X=X,\n",
    "                       y=y,\n",
    "                       X_holdout=X_holdout,\n",
    "                       y_holdout=y_holdout)\n",
    "\n",
    "log_loss_GBM_holdout, F1_GBM_holdout, accuracy_GBM_holdout, y_pred_GBM = \\\n",
    "evaluate_model_holdout(model=GBM,\n",
    "                       X=X,\n",
    "                       y=y,\n",
    "                       X_holdout=X_holdout,\n",
    "                       y_holdout=y_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7419c493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression:\n",
      "Log loss: 0.36\n",
      "F1 score: 0.20\n",
      "Accuracy: 0.88\n",
      "\n",
      "Gradient boost machine:\n",
      "Log loss: 0.38\n",
      "F1 score: 0.26\n",
      "Accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "print('Logistic regression:')\n",
    "print(f'Log loss: {log_loss_LR_holdout:0.2f}')\n",
    "print(f'F1 score: {F1_LR_holdout:0.2f}')\n",
    "print(f'Accuracy: {accuracy_LR_holdout:0.2f}')\n",
    "print()\n",
    "print('Gradient boost machine:')\n",
    "print(f'Log loss: {log_loss_GBM_holdout:0.2f}')\n",
    "print(f'F1 score: {F1_GBM_holdout:0.2f}')\n",
    "print(f'Accuracy: {accuracy_GBM_holdout:0.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16c9f4a",
   "metadata": {},
   "source": [
    "Same trend as CV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e86ff9",
   "metadata": {},
   "source": [
    "Let's look at classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e7e86dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for: Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94      1631\n",
      "           1       0.88      0.11      0.20       247\n",
      "\n",
      "    accuracy                           0.88      1878\n",
      "   macro avg       0.88      0.56      0.57      1878\n",
      "weighted avg       0.88      0.88      0.84      1878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification report for: Logistic Regression')\n",
    "print(classification_report(y_holdout, y_pred_LR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "73354487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for: GBM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94      1631\n",
      "           1       0.80      0.16      0.26       247\n",
      "\n",
      "    accuracy                           0.88      1878\n",
      "   macro avg       0.84      0.58      0.60      1878\n",
      "weighted avg       0.87      0.88      0.85      1878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification report for: GBM')\n",
    "print(classification_report(y_holdout, y_pred_GBM))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8da3b16",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bee441",
   "metadata": {},
   "source": [
    "We'll do a simple NN without any hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "76401765",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-11 17:53:58.665551: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-11 17:53:59.732894: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "235/235 [==============================] - 31s 129ms/step - loss: 0.3943 - accuracy: 0.8660\n",
      "Epoch 2/5\n",
      "235/235 [==============================] - 30s 129ms/step - loss: 0.2310 - accuracy: 0.9066\n",
      "Epoch 3/5\n",
      "235/235 [==============================] - 31s 132ms/step - loss: 0.0790 - accuracy: 0.9771\n",
      "Epoch 4/5\n",
      "235/235 [==============================] - 30s 127ms/step - loss: 0.0159 - accuracy: 0.9984\n",
      "Epoch 5/5\n",
      "235/235 [==============================] - 29s 125ms/step - loss: 0.0046 - accuracy: 0.9995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcc69ebaeb0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the model\n",
    "NN = keras.Sequential([\n",
    "     keras.layers.Dense(5000, input_shape=(np.shape(X)[1],), activation='relu'), \n",
    "     keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "NN.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "NN.fit(X, y, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "72260746",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/WHR/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 1s 17ms/step - loss: 0.5769 - accuracy: 0.8397\n"
     ]
    }
   ],
   "source": [
    "# Get prediction and probability for the test dataset\n",
    "y_pred_NN = np.transpose(NN.predict_classes(X_holdout))[0]\n",
    "y_pred_prob_NN = np.transpose(NN.predict(X_holdout))[0]\n",
    "\n",
    "# Get stats\n",
    "log_loss_NN_holdout = log_loss(y_holdout, y_pred_prob_NN)\n",
    "F1_NN_holdout = f1_score(y_holdout, y_pred_NN)\n",
    "accuracy_NN_holdout = NN.evaluate(X_holdout, y_holdout)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a850a0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network:\n",
      "Log loss: 0.5768663558501774\n",
      "F1 score: 0.26405867970660146\n",
      "Accuracy: 0.8397231101989746\n"
     ]
    }
   ],
   "source": [
    "print('Neural network:')\n",
    "print(f'Log loss: {log_loss_NN_holdout}')\n",
    "print(f'F1 score: {F1_NN_holdout}')\n",
    "print(f'Accuracy: {accuracy_NN_holdout}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc59f7c",
   "metadata": {},
   "source": [
    "We see that compared to logistic regression and GBM, NN gives higher log loss and accuracy, but F1 score is higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b5fccc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for: NN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91      1631\n",
      "           1       0.33      0.22      0.26       247\n",
      "\n",
      "    accuracy                           0.84      1878\n",
      "   macro avg       0.61      0.58      0.59      1878\n",
      "weighted avg       0.81      0.84      0.83      1878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification report for: NN')\n",
    "print(classification_report(y_holdout, y_pred_NN))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8ee439",
   "metadata": {},
   "source": [
    "# Three Most Important Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06ce032",
   "metadata": {},
   "source": [
    "Since all three models give comparable performance in terms of log loss, F1 score, and accuracy, let's see what the three most important features are for the ML models (not straightforward in NN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f5a07e",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e33cf36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression:\n",
      "1st important feature:\n",
      "purpose_cat_debt consolidation small business, abs(coef): 4.42\n",
      "2nd important feature:\n",
      "purpose_cat_credit card small business, abs(coef): 2.70\n",
      "3rd important feature:\n",
      "purpose_cat_home improvement small business, abs(coef): 2.65\n"
     ]
    }
   ],
   "source": [
    "feature_indices = np.argsort(np.abs(LR.coef_[0]))\n",
    "print('Linear regression:')\n",
    "print(f'1st important feature:')\n",
    "print(f'{X.columns[feature_indices[-1]]}, abs(coef): {np.abs(LR.coef_[0])[feature_indices[-1]]:0.2f}')\n",
    "print(f'2nd important feature:')\n",
    "print(f'{X.columns[feature_indices[-2]]}, abs(coef): {np.abs(LR.coef_[0])[feature_indices[-2]]:0.2f}')\n",
    "print(f'3rd important feature:')\n",
    "print(f'{X.columns[feature_indices[-3]]}, abs(coef): {np.abs(LR.coef_[0])[feature_indices[-3]]:0.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e49ed0",
   "metadata": {},
   "source": [
    "### GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "528999d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM:\n",
      "1st important feature:\n",
      "purpose_cat_debt consolidation small business, abs(coef): 0.27\n",
      "2nd important feature:\n",
      "purpose_cat_credit card small business, abs(coef): 0.06\n",
      "3rd important feature:\n",
      "total_acc, abs(coef): 0.05\n"
     ]
    }
   ],
   "source": [
    "feature_indices = np.argsort(GBM.feature_importances_)\n",
    "print('GBM:')\n",
    "print(f'1st important feature:')\n",
    "print(f'{X.columns[feature_indices[-1]]}, abs(coef): {GBM.feature_importances_[feature_indices[-1]]:0.2f}')\n",
    "print(f'2nd important feature:')\n",
    "print(f'{X.columns[feature_indices[-2]]}, abs(coef): {GBM.feature_importances_[feature_indices[-2]]:0.2f}')\n",
    "print(f'3rd important feature:')\n",
    "print(f'{X.columns[feature_indices[-3]]}, abs(coef): {GBM.feature_importances_[feature_indices[-3]]:0.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df6205f",
   "metadata": {},
   "source": [
    "# Recommended Model to Use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1637e5dc",
   "metadata": {},
   "source": [
    "Considering that the three models have similar performance based on F1 score, log loss, and accuracy, I would recommend using **logistic regression model** because of its few characteristics.\n",
    "- Easy interpretation of important features\n",
    "- Relatively fast training (in case more training data becomes available) \n",
    "- Computationally efficient prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1862d97",
   "metadata": {},
   "source": [
    "# One Last Thing to Try: Oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6da9f1f",
   "metadata": {},
   "source": [
    "I suspect that the relatively low F1 score in all of the models is due to the imbalance in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fea9bc57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 8204 fulfillments\n",
      "There are 1184 defaults\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {df_raw['is_bad'][df_raw['is_bad']==0].count()} fulfillments\")\n",
    "print(f\"There are {df_raw['is_bad'][df_raw['is_bad']==1].count()} defaults\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2a502636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partition df_combined into 'is_bad'=0 and 1\n",
    "df_isbad_0 = df_combined[df_combined['is_bad']==0]\n",
    "df_isbad_1 = df_combined[df_combined['is_bad']==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65b9fc7",
   "metadata": {},
   "source": [
    "Oversample ```df_isbad_1``` using the ```sample``` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e7980657",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_isbad_0 = np.shape(df_isbad_0)[0]\n",
    "df_isbad_1_oversample = df_isbad_1.sample(n_isbad_0, replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f4a39a",
   "metadata": {},
   "source": [
    "Check the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b5e52c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fulfillment: 8204\n",
      "Default (oversampled): 8204\n"
     ]
    }
   ],
   "source": [
    "print(f'Fulfillment: {np.shape(df_isbad_0)[0]}')\n",
    "print(f'Default (oversampled): {np.shape(df_isbad_1_oversample)[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8109336",
   "metadata": {},
   "source": [
    "Nice, now combine the two and test the models (just do the holdout this time) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f5a92f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oversample = pd.concat([df_isbad_0,df_isbad_1_oversample],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ce17f863",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_oversample = df_oversample.drop('is_bad',axis=1)\n",
    "y_oversample = df_oversample['is_bad']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_oversample, y_oversample, \n",
    "                                                    test_size=0.2, stratify=y_oversample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "674a381c",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss_LR_oversample, F1_LR_oversample, accuracy_LR_oversample, y_pred_LR_oversample = \\\n",
    "evaluate_model_holdout(model=LR,\n",
    "                       X=X_train,\n",
    "                       y=y_train,\n",
    "                       X_holdout=X_test,\n",
    "                       y_holdout=y_test)\n",
    "\n",
    "log_loss_GBM_oversample, F1_GBM_oversample, accuracy_GBM_oversample, y_pred_GBM_oversample = \\\n",
    "evaluate_model_holdout(model=GBM,\n",
    "                       X=X_train,\n",
    "                       y=y_train,\n",
    "                       X_holdout=X_test,\n",
    "                       y_holdout=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "adc20e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression:\n",
      "Log loss: 0.34\n",
      "F1 score: 0.92\n",
      "Accuracy: 0.92\n",
      "\n",
      "Gradient boost machine:\n",
      "Log loss: 0.57\n",
      "F1 score: 0.66\n",
      "Accuracy: 0.69\n"
     ]
    }
   ],
   "source": [
    "print('Logistic regression:')\n",
    "print(f'Log loss: {log_loss_LR_oversample:0.2f}')\n",
    "print(f'F1 score: {F1_LR_oversample:0.2f}')\n",
    "print(f'Accuracy: {accuracy_LR_oversample:0.2f}')\n",
    "print()\n",
    "print('Gradient boost machine:')\n",
    "print(f'Log loss: {log_loss_GBM_oversample:0.2f}')\n",
    "print(f'F1 score: {F1_GBM_oversample:0.2f}')\n",
    "print(f'Accuracy: {accuracy_GBM_oversample:0.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c2a1d4d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for: Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.88      0.91      1641\n",
      "           1       0.89      0.95      0.92      1641\n",
      "\n",
      "    accuracy                           0.92      3282\n",
      "   macro avg       0.92      0.92      0.92      3282\n",
      "weighted avg       0.92      0.92      0.92      3282\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification report for: Logistic Regression')\n",
    "print(classification_report(y_test, y_pred_LR_oversample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ec0ca0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for: GBM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.77      0.71      1641\n",
      "           1       0.73      0.61      0.66      1641\n",
      "\n",
      "    accuracy                           0.69      3282\n",
      "   macro avg       0.70      0.69      0.69      3282\n",
      "weighted avg       0.70      0.69      0.69      3282\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification report for: GBM')\n",
    "print(classification_report(y_test, y_pred_GBM_oversample))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a85687",
   "metadata": {},
   "source": [
    "We now see that with the oversampling, logistic regression outperforms GBM by all three measures of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932113eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
